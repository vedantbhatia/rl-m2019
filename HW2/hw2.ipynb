{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(s):\n",
    "    if(s[0]<0 or s[0]>4):\n",
    "        return(-1)\n",
    "    if(s[1]<0 or s[1]>4):\n",
    "        return(-1)\n",
    "    return(0)\n",
    "def display(arr):\n",
    "    np.set_printoptions(precision=5)\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            print(\"{0:0.2f}\".format(arr[i,j]),end=\"   \")\n",
    "        print()\n",
    "def policy_value():\n",
    "    gamma = 0.9\n",
    "    gridworld = np.zeros((5,5))\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    special_states = {}\n",
    "    special_rewards = {}\n",
    "    special_states[(0,1)]=(4,1)\n",
    "    special_rewards[(0,1)]=10\n",
    "    special_states[(0,3)]=(2,3) \n",
    "    special_rewards[(0,3)]=5 \n",
    "    changes = True\n",
    "    count = 0\n",
    "    while(changes):\n",
    "        count+=1\n",
    "        changes= False\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                total = 0\n",
    "                best_value = 0\n",
    "                best_move = 0\n",
    "                for d in range(4):\n",
    "                    state = (i,j)\n",
    "                    dx = mx[d]\n",
    "                    dy = my[d]\n",
    "                    dest = (dx,dy) \n",
    "                    new_s = np.add(state,dest) if state not in special_states else special_states[state]\n",
    "\n",
    "                    r = get_reward(new_s) if state not in special_states else special_rewards[state]\n",
    "                    if(r!=-1):\n",
    "                        r += gamma*gridworld[new_s[0],new_s[1]]\n",
    "                    else:\n",
    "                        new_s = np.copy(state)\n",
    "                        \n",
    "                    if(r>best_value):\n",
    "                        best_value=r\n",
    "                        best_move=new_s\n",
    "                \n",
    "                if(np.abs(best_value-gridworld[i,j])>=0.001*gridworld[i,j]):\n",
    "                    changes = True\n",
    "                gridworld[i,j]=best_value\n",
    "        if(count%10==0):\n",
    "            display(gridworld)\n",
    "            print(\"count\",count)\n",
    "    return(gridworld)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.79   24.29   21.86   19.29   17.36   \n",
      "19.61   21.86   19.68   17.71   15.94   \n",
      "17.65   19.68   17.71   15.94   14.35   \n",
      "15.88   17.71   15.94   14.35   12.91   \n",
      "14.29   15.94   14.35   12.91   11.62   \n",
      "count 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[21.95416, 24.40413, 21.96371, 19.40413, 17.46371],\n",
       "       [19.75875, 21.96371, 19.76734, 17.79061, 16.01155],\n",
       "       [17.78287, 19.76734, 17.79061, 16.01155, 14.41039],\n",
       "       [16.00459, 17.79061, 16.01155, 14.41039, 12.96935],\n",
       "       [14.40413, 16.01155, 14.41039, 12.96935, 11.67242]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_equation():\n",
    "    gamma = 0.9\n",
    "    # defining possible moves for an agent not in either of the special positions by (mx[i],my[i])\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    # defining possible moves for agent in the special states A and B. special_states gives destination on any move, and special_rewards gives reward\n",
    "    special_states = {}\n",
    "    special_rewards = {}\n",
    "    special_states[(0,1)]=(4,1)\n",
    "    special_rewards[(0,1)]=10\n",
    "    special_states[(0,3)]=(2,3) \n",
    "    special_rewards[(0,3)]=5 \n",
    "    # we will have to solve a system of linear equations of the for ax=b where a is the coefficient matrix and b is the dependent variable value matrix. as there are 25 states, there are 25 V_pi's to solve for, hence a 25x25 matrix of coefficients\n",
    "    coeffs_matrix = np.zeros((25,25))\n",
    "    constants_matrix = np.zeros((25,1))\n",
    "    # iterating over all the states\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            # current state\n",
    "            state = (i,j)\n",
    "            # we can represent each of the 25 states' coeffs in a 5x5 grid, and later unravel it to a 1x25 list \n",
    "            coeffs = np.zeros((5,5))\n",
    "            # our equation for a state i is: v_i = SUM(prob_action*SUM(p(s',r|s,a)*[r + gamma*v_s'])).\n",
    "            # here p(s',r|s,a)=1 for a given s,a as there is only one possible successor state (and corresponding reward) for each state s and action a\n",
    "            coeffs[state]+=1\n",
    "            results = np.zeros((1,1))\n",
    "            for d in range(4):\n",
    "                dx = mx[d]\n",
    "                dy = my[d]\n",
    "                dest = (dx,dy)\n",
    "                new_s = np.add(state,dest) if state not in special_states else special_states[state]\n",
    "                r = get_reward(new_s) if state not in special_states else special_rewards[state]\n",
    "                results[0,0]+=0.25*r\n",
    "                if(r==-1):\n",
    "                    new_s=np.copy(state)\n",
    "                coeffs[new_s[0],new_s[1]]+=-0.25*gamma\n",
    "            #add each state's coeff and constant matrix to the global one\n",
    "            coeffs_matrix[i*5+j,:]=coeffs.ravel()\n",
    "            constants_matrix[i*5+j,:]=results.ravel()\n",
    "    display(coeffs_matrix)\n",
    "    return(coeffs_matrix,constants_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   1.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.90   0.00   0.00   0.00   \n",
      "0.00   -0.23   0.78   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   1.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.90   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   -0.23   0.55   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "-0.23   0.00   0.00   0.00   0.00   0.78   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.78   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.78   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   0.00   0.00   0.00   0.00   -0.23   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.55   -0.23   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   -0.23   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   -0.23   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   -0.23   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.55   \n"
     ]
    }
   ],
   "source": [
    "a,b=get_linear_equation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 25) (25, 1)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape,b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linalg.solve(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.31   8.79   4.43   5.32   1.49   \n",
      "1.52   2.99   2.25   1.91   0.55   \n",
      "0.05   0.74   0.67   0.36   -0.40   \n",
      "-0.97   -0.44   -0.35   -0.59   -1.18   \n",
      "-1.86   -1.35   -1.23   -1.42   -1.98   \n"
     ]
    }
   ],
   "source": [
    "display(x.reshape(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonlinear_equation():\n",
    "    gamma = 0.9\n",
    "    # defining possible moves for an agent not in either of the special positions by (mx[i],my[i])\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    # defining possible moves for agent in the special states A and B. special_states gives destination on any move, and special_rewards gives reward\n",
    "    special_states = {}\n",
    "    special_rewards = {}\n",
    "    special_states[(0,1)]=(4,1)\n",
    "    special_rewards[(0,1)]=10\n",
    "    special_states[(0,3)]=(2,3) \n",
    "    special_rewards[(0,3)]=5 \n",
    "    # we will have to solve a system of linear equations of the for ax=b where a is the coefficient matrix and b is the dependent variable value matrix. as there are 25 states, there are 25 V_pi's to solve for, hence a 25x25 matrix of coefficients\n",
    "    coeffs_matrix = np.zeros((100,25))\n",
    "    constants_matrix = np.zeros((100,1))\n",
    "    # iterating over all the states\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            # current state\n",
    "            state = (i,j)\n",
    "            # we can represent each of the 25 states' coeffs in a 5x5 grid, and later unravel it to a 1x25 list \n",
    "            coeffs = np.zeros((5,5))\n",
    "            # our equation for a state i is: v_i = SUM(prob_action*SUM(p(s',r|s,a)*[r + gamma*v_s'])).\n",
    "            # here p(s',r|s,a)=1 for a given s,a as there is only one possible successor state (and corresponding reward) for each state s and action a\n",
    "            coeffs[state]+=1\n",
    "            results = np.zeros((1,1))\n",
    "            for d in range(4):\n",
    "                dx = mx[d]\n",
    "                dy = my[d]\n",
    "                dest = (dx,dy)\n",
    "                new_s = np.add(state,dest) if state not in special_states else special_states[state]\n",
    "                r = get_reward(new_s) if state not in special_states else special_rewards[state]\n",
    "                results[0,0]+=0.25*r\n",
    "                if(r==-1):\n",
    "                    new_s=np.copy(state)\n",
    "                coeffs[new_s[0],new_s[1]]+=-0.25*gamma\n",
    "                #add each state's coeff and constant matrix to the global one\n",
    "                coeffs_matrix[i*5+d+j,:]=coeffs.ravel()\n",
    "                constants_matrix[i*5+d+j,:]=results.ravel()\n",
    "#     display(coeffs_matrix)\n",
    "    return(coeffs_matrix,constants_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = get_nonlinear_equation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 25) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape,b.shape)\n",
    "c = np.ones((25,1))\n",
    "# import scipy.optimize as opt\n",
    "# print(a.T.shape,b.ravel().shape)\n",
    "x = scipy.optimize.linprog(c,-a,-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     con: array([], dtype=float64)\n",
       "     fun: 4.8563525351304815\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 7\n",
       "   slack: array([ 2.50000e-01, -3.52163e-13,  2.50000e-01, -7.72715e-14,\n",
       "        2.50000e-01,  1.90889e-13,  4.79616e-14,  1.90889e-13,\n",
       "       -3.44169e-15,  1.91026e-13,  1.94335e-13,  6.95000e-14,\n",
       "        1.94335e-13, -1.45023e-14,  1.95608e-13,  1.97973e-13,\n",
       "        7.66817e-14,  1.97973e-13,  1.96301e-14,  2.10194e-13,\n",
       "        2.26518e-13,  2.34344e-14,  2.26518e-13,  5.48485e-14,\n",
       "        1.70694e-13,  2.50000e-01,  2.49271e-01,  4.99271e-01,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00,\n",
       "       -0.00000e+00, -0.00000e+00, -0.00000e+00, -0.00000e+00])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([3.04516e-13, 2.50144e+00, 3.04516e-13, 1.26440e+00, 3.04594e-13,\n",
       "       2.59405e-13, 5.62825e-01, 2.59405e-13, 2.84491e-01, 2.59560e-13,\n",
       "       2.52701e-13, 1.26636e-01, 2.52701e-13, 6.40104e-02, 2.54009e-13,\n",
       "       2.54831e-13, 2.84930e-02, 2.54831e-13, 1.44023e-02, 2.67346e-13,\n",
       "       2.83855e-13, 6.41092e-03, 2.83855e-13, 3.24052e-03, 2.30846e-13])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_state(s):\n",
    "    if(s[0]>=0 and s[0]<4):\n",
    "        if(s[1]>=0 and s[1]<4):\n",
    "            return(True)\n",
    "    return(False)\n",
    "def terminal(s):\n",
    "    if(s[0]==0 and s[1]==0):\n",
    "        return(True)\n",
    "    if(s[0]==3 and s[1]==3):\n",
    "        return(True)\n",
    "    return(False)\n",
    "def policy_evaluation(gridworld=None,policy=None):\n",
    "    gamma = 1\n",
    "    if(gridworld is None):\n",
    "        gridworld = np.zeros((4,4))\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    if(policy is None):\n",
    "        policy = np.ones((4,4,4))*0.25\n",
    "    changes = True\n",
    "    count = 0\n",
    "    while(changes):\n",
    "        count+=1\n",
    "        changes= False\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                total = 0\n",
    "                state = (i,j)\n",
    "                if(terminal(state)):\n",
    "                        continue\n",
    "                for d in range(4):\n",
    "                    dx = mx[d]\n",
    "                    dy = my[d]\n",
    "                    dest = (dx,dy) \n",
    "                    new_s = np.add(state,dest) \n",
    "                    if(not valid_state(new_s)):\n",
    "                        new_s=state\n",
    "                    r=-1\n",
    "#                     if(terminal(new_s)):\n",
    "#                         r=0\n",
    "                    r += gamma*gridworld[new_s[0],new_s[1]]\n",
    "                    total+=policy[i,j,d]*r\n",
    "                if(np.abs(total-gridworld[i,j])>0.01):\n",
    "                    changes = True\n",
    "                gridworld[i,j]=total\n",
    "        if(count%10==0):\n",
    "            display(gridworld)\n",
    "            print(\"evalutation count\",count)\n",
    "    return(gridworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00   -7.83   -11.12   -12.23   \n",
      "-7.83   -10.42   -11.77   -11.86   \n",
      "-11.12   -11.77   -11.05   -8.81   \n",
      "-12.23   -11.86   -8.81   0.00   \n",
      "evalutation count 10\n",
      "0.00   -11.43   -16.30   -17.93   \n",
      "-11.43   -14.84   -16.57   -16.61   \n",
      "-16.30   -16.57   -15.11   -11.84   \n",
      "-17.93   -16.61   -11.84   0.00   \n",
      "evalutation count 20\n",
      "0.00   -12.93   -18.46   -20.30   \n",
      "-12.93   -16.68   -18.57   -18.59   \n",
      "-18.46   -18.57   -16.79   -13.10   \n",
      "-20.30   -18.59   -13.10   0.00   \n",
      "evalutation count 30\n",
      "0.00   -13.55   -19.36   -21.29   \n",
      "-13.55   -17.45   -19.40   -19.41   \n",
      "-19.36   -19.40   -17.50   -13.62   \n",
      "-21.29   -19.41   -13.62   0.00   \n",
      "evalutation count 40\n",
      "0.00   -13.81   -19.73   -21.71   \n",
      "-13.81   -17.77   -19.75   -19.75   \n",
      "-19.73   -19.75   -17.79   -13.84   \n",
      "-21.71   -19.75   -13.84   0.00   \n",
      "evalutation count 50\n",
      "0.00   -13.92   -19.89   -21.88   \n",
      "-13.92   -17.90   -19.90   -19.90   \n",
      "-19.89   -19.90   -17.91   -13.93   \n",
      "-21.88   -19.90   -13.93   0.00   \n",
      "evalutation count 60\n"
     ]
    }
   ],
   "source": [
    "grid = policy_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy(policy):\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    \n",
    "    z = np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            val = np.argmax(policy[i,j,:])\n",
    "    #         print(val)\n",
    "#             z[i,j]=val\n",
    "            print(\"({0},{1})\".format(mx[val],my[val]),end=\" \")\n",
    "        print()\n",
    "#     plt.contour(z)\n",
    "#     plt.show()\n",
    "#     print(z)\n",
    "def policy_improvement(gridworld):\n",
    "    stable = False\n",
    "    policy = []\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    policy = np.ones((4,4,4))*0.25\n",
    "#     policy[:,:,0]=\n",
    "    while(not stable):\n",
    "        stable=True\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                state = (i,j)\n",
    "                if(terminal(state)):\n",
    "                    continue\n",
    "                old_action = np.argmax(policy[i,j,:])\n",
    "                old_actions = np.where(policy[i,j,:]==policy[i,j,:].max())[0]\n",
    "#                 print(old_actions,i,j)\n",
    "                best_value = -np.inf\n",
    "                best_move = None\n",
    "                for d in range(4):\n",
    "                    dest = (mx[d],my[d])\n",
    "                    new_s = np.add(state,dest)\n",
    "                    if(not valid_state(new_s)):\n",
    "                        new_s =  state\n",
    "                    if(terminal(new_s)):\n",
    "                        r = policy[i,j,d]*(gridworld[new_s[0],new_s[1]])\n",
    "                    else:\n",
    "                        r = policy[i,j,d]*(-1+gridworld[new_s[0],new_s[1]])\n",
    "                    if(r>best_value):\n",
    "#                         print(best_value,r,d)\n",
    "                        best_value = r\n",
    "                        best_move = d\n",
    "                policy[i,j,:]=0\n",
    "                policy[i,j,best_move]=1\n",
    "#                 stable = True\n",
    "                if(best_move not in old_actions):\n",
    "                    stable=False\n",
    "#                     print(best_move,old_action)\n",
    "                \n",
    "                        \n",
    "        if(not stable):\n",
    "            print(\"not stable\")\n",
    "            display(gridworld)\n",
    "            gridworld=policy_evaluation(gridworld,policy)\n",
    "            display(gridworld)\n",
    "            print_policy(policy)\n",
    "    return(policy)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1,0) (0,-1) (0,-1) (0,-1) \n",
      "(-1,0) (0,-1) (-1,0) (-1,0) \n",
      "(-1,0) (-1,0) (-1,0) (1,0) \n",
      "(-1,0) (-1,0) (0,1) (-1,0) \n"
     ]
    }
   ],
   "source": [
    "p = policy_improvement(grid)\n",
    "print_policy(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 0   0 -1   0 -1   0 -1   \n",
      "-1 0   0 -1   -1 0   -1 0   \n",
      "-1 0   -1 0   -1 0   1 0   \n",
      "-1 0   -1 0   0 1   -1 0   \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration():\n",
    "    stable = False\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    gridworld = np.ones((4,4))\n",
    "    gridworld[0,0]=0\n",
    "    gridworld[3,3]=0\n",
    "    \n",
    "    while(not stable):\n",
    "        print(gridworld)\n",
    "        stable = True\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                state = (i,j)\n",
    "                old = gridworld[i,j]\n",
    "                if(terminal(state)):\n",
    "                    continue\n",
    "                best_value = -np.inf\n",
    "                for d in range(4):\n",
    "#                     d = int(policy[i,j])\n",
    "                    dest = (mx[d],my[d])\n",
    "                    new_s = np.add(state,dest)\n",
    "                    \n",
    "                    if(not valid_state(new_s)):\n",
    "                        new_s =  state\n",
    "    #                 if(terminal(new_s)):\n",
    "    #                     r = (gridworld[new_s[0],new_s[1]])\n",
    "    #                 else:\n",
    "                    r = -1+gridworld[new_s[0],new_s[1]]\n",
    "                    if(r>best_value):\n",
    "    #                         print(best_value,r,d)\n",
    "                        best_value = r\n",
    "                        best_move = d    \n",
    "            \n",
    "                gridworld[i,j]=best_value\n",
    "                if(np.abs(old-best_value)>0.01):\n",
    "                          stable=False\n",
    "                policy[i][j]=best_move\n",
    "#                 if():\n",
    "\n",
    "    return(gridworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 0.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1.  0.]]\n",
      "[[ 0. -1. -2. -2.]\n",
      " [-1. -2. -2. -2.]\n",
      " [-2. -2. -2. -1.]\n",
      " [-2. -2. -1.  0.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -2., -3.],\n",
       "       [-1., -2., -3., -2.],\n",
       "       [-2., -3., -2., -1.],\n",
       "       [-3., -2., -1.,  0.]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = [-1,0,0,1]\n",
    "my = [0,1,-1,0]    \n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        for d in range(4):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "prob_poi = np.zeros((3,21))\n",
    "vals = [2,3,4]\n",
    "for i in range(3):\n",
    "    for j in range(21):\n",
    "        prob_poi[i,j]= poisson.pmf(j,vals[i])\n",
    "prob_poi>0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_state(s):\n",
    "    if(s[0]>=0 and s[0]<21):\n",
    "        if(s[1]>=0 and s[1]<21):\n",
    "            return(True)\n",
    "    return(False)\n",
    "def make_valid(s):\n",
    "    for i in range(2):\n",
    "        if(s[i]<0):\n",
    "            s[i]=0\n",
    "        if(s[i]>20):\n",
    "            s[i]=20\n",
    "    return(s)\n",
    "def jacks_policy_evaluation(gridworld=None,probs=None):\n",
    "    gamma = 0.9\n",
    "    if(gridworld is None):\n",
    "        gridworld = np.zeros((21,21))\n",
    "    if(probs is None):\n",
    "        probs = np.zeros((21,21)) \n",
    "#         probs[:,:,0] = 1\n",
    "    rewards = np.zeros((21,21))\n",
    "\n",
    "    changes = True\n",
    "    count = 0\n",
    "    while(changes):\n",
    "        count+=1\n",
    "        changes= False\n",
    "        for i in range(21):\n",
    "            for j in range(21):\n",
    "                total = 0                \n",
    "                for req_a in range(9):\n",
    "                    for req_b in range(9):\n",
    "                        for ret_a in range(9):\n",
    "                            for ret_b in range(9):\n",
    "                                state = [i,j]\n",
    "                                prob = prob_poi[1,req_a]*prob_poi[1,ret_a]*prob_poi[0,ret_b]*prob_poi[2,req_b]\n",
    "                                add1=10*min(state[0],req_a)\n",
    "                                state[0]=max(state[0]-req_a,0)\n",
    "                                add2=10*min(state[1],req_b)\n",
    "                                state[1]=max(state[1]-req_b,0)\n",
    "                                state[0]=min(20,ret_a+state[0])\n",
    "                                state[1]=min(20,ret_b+state[1])\n",
    "#                                 for d in range(11):\n",
    "                                d = int(probs[state[0],state[1]])\n",
    "#                                     if(probs[state[0],state[1],d]>0):\n",
    "                                r = -2*d +add1+add2\n",
    "                                if(d<6):\n",
    "                                    move = (-d,d)\n",
    "                                else:\n",
    "                                    r = -2*(d-5) +add1+add2\n",
    "                                    move = (d-5,5-d)\n",
    "                                new_s = np.add(state,move)\n",
    "            #                     print(new_s)\n",
    "                                if(not valid_state(new_s)):\n",
    "                                    new_s = make_valid(new_s)\n",
    "                                r += gamma*gridworld[new_s[0],new_s[1]]\n",
    "                                total+=prob*r\n",
    "            \n",
    "                if(np.abs(total-gridworld[i,j])>1):\n",
    "                    changes = True\n",
    "                gridworld[i,j]=total\n",
    "        print(count,changes)\n",
    "        if(count%100==0):\n",
    "#             display(gridworld)\n",
    "            print(\"count\",count)\n",
    "        if(count==1000):\n",
    "            break\n",
    "    return(gridworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 True\n",
      "6 True\n",
      "7 True\n",
      "8 True\n",
      "9 True\n",
      "10 True\n",
      "11 True\n",
      "12 True\n",
      "13 True\n",
      "14 True\n",
      "15 True\n",
      "16 True\n",
      "17 True\n",
      "18 True\n",
      "19 True\n",
      "20 True\n",
      "21 False\n"
     ]
    }
   ],
   "source": [
    "grid =jacks_policy_evaluation()\n",
    "grid\n",
    "grid2 = np.copy(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacks_policy_improvement(gridworld):\n",
    "    gamma = 0.9\n",
    "#     gridworld = np.zeros((21,21))\n",
    "    probs = np.zeros((21,21))\n",
    "    stable = False\n",
    "    count = 0\n",
    "    while(not stable):\n",
    "        stable=True\n",
    "        count+=1\n",
    "        for i in range(21):\n",
    "            for j in range(21):\n",
    "                total = 0\n",
    "                best_move=0\n",
    "                best_reward = -np.inf               \n",
    "                for req_a in range(9):\n",
    "                    for req_b in range(9):\n",
    "                        for ret_a in range(9):\n",
    "                            for ret_b in range(9):\n",
    "                                state = [i,j]\n",
    "                                add1=10*min(state[0],req_a)\n",
    "                                state[0]=max(state[0]-req_a,0)\n",
    "                                add2=10*min(state[1],req_b)\n",
    "                                state[1]=max(state[1]-req_b,0)\n",
    "                                state[0]=min(20,ret_a+state[0])\n",
    "                                state[1]=min(20,ret_b+state[1])\n",
    "                                prob = prob_poi[1,req_a]*prob_poi[1,ret_a]*prob_poi[0,ret_b]*prob_poi[2,req_b]\n",
    "                                for d in range(11):\n",
    "#                                 d = int(probs[state[0],state[1]])\n",
    "#                                     if(probs[state[0],state[1],d]>0):\n",
    "                                    r = -2*d +add1+add2\n",
    "                                    if(d<6):\n",
    "                                        move = (-d,d)\n",
    "                                    else:\n",
    "                                        r = -2*(d-5) +add1+add2\n",
    "                                        move = (d-5,5-d)\n",
    "                                    new_s = np.add(state,move) \n",
    "                                    if(not valid_state(new_s)):\n",
    "                                        new_s = make_valid(new_s)\n",
    "                                    r += gamma*gridworld[new_s[0],new_s[1]]\n",
    "                                    total=prob*r\n",
    "                                    if(total>best_reward):\n",
    "                                        best_reward=total\n",
    "                                        best_move=d\n",
    "                old_action = probs[i,j]\n",
    "                probs[i,j]=best_move\n",
    "                if(old_action!=best_move):\n",
    "                    stable=False\n",
    "        if(not stable):\n",
    "            gridworld=jacks_policy_evaluation(gridworld,probs)\n",
    "#         if(count%100==0):\n",
    "#     #             display(gridworld)\n",
    "#             print(\"count\",count)\n",
    "        print(count,stable)\n",
    "#         plot_policy(probs)\n",
    "    return(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 True\n",
      "6 True\n",
      "7 True\n",
      "8 False\n",
      "1 False\n",
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 False\n",
      "2 False\n",
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 False\n",
      "3 False\n",
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 True\n",
      "6 False\n",
      "4 False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-322-0dda906824ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacks_policy_improvement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-321-850f2a877345>\u001b[0m in \u001b[0;36mjacks_policy_improvement\u001b[0;34m(gridworld)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0madd1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0madd2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                     \u001b[0mnew_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                                     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mvalid_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                         \u001b[0mnew_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy = jacks_policy_improvement(grid)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_policy(policy):\n",
    "#     z = np.zeros((21,21))\n",
    "#     for i in range(21):\n",
    "#         for j in range(21):\n",
    "#             val = np.argmax(policy[i,j,:])\n",
    "#     #         print(val)\n",
    "#             if(val>5):\n",
    "#                 val = 5-val\n",
    "#             z[i,j]=val\n",
    "    plt.contour(policy)\n",
    "    plt.show()\n",
    "#     print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
