{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(s):\n",
    "    if(s[0]<0 or s[0]>4):\n",
    "        return(-1)\n",
    "    if(s[1]<0 or s[1]>4):\n",
    "        return(-1)\n",
    "    return(0)\n",
    "def display(arr):\n",
    "    np.set_printoptions(precision=5)\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            print(\"{0:0.2f}\".format(arr[i,j]),end=\"   \")\n",
    "        print()\n",
    "def policy_value():\n",
    "    gamma = 0.9\n",
    "    gridworld = np.zeros((5,5))\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    special_states = {}\n",
    "    special_rewards = {}\n",
    "    special_states[(0,1)]=(4,1)\n",
    "    special_rewards[(0,1)]=10\n",
    "    special_states[(0,3)]=(2,3) \n",
    "    special_rewards[(0,3)]=5 \n",
    "    changes = True\n",
    "    count = 0\n",
    "    while(changes):\n",
    "        count+=1\n",
    "        changes= False\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                total = 0\n",
    "                best_value = 0\n",
    "                best_move = 0\n",
    "                for d in range(4):\n",
    "                    state = (i,j)\n",
    "                    dx = mx[d]\n",
    "                    dy = my[d]\n",
    "                    dest = (dx,dy) \n",
    "                    new_s = np.add(state,dest) if state not in special_states else special_states[state]\n",
    "\n",
    "                    r = get_reward(new_s) if state not in special_states else special_rewards[state]\n",
    "                    if(r!=-1):\n",
    "                        r += gamma*gridworld[new_s[0],new_s[1]]\n",
    "                    else:\n",
    "                        new_s = np.copy(state)\n",
    "                        \n",
    "                    if(r>best_value):\n",
    "                        best_value=r\n",
    "                        best_move=new_s\n",
    "                \n",
    "                if(np.abs(best_value-gridworld[i,j])>=0.001*gridworld[i,j]):\n",
    "                    changes = True\n",
    "                gridworld[i,j]=best_value\n",
    "        if(count%10==0):\n",
    "            display(gridworld)\n",
    "            print(\"count\",count)\n",
    "    return(gridworld)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.79   24.29   21.86   19.29   17.36   \n",
      "19.61   21.86   19.68   17.71   15.94   \n",
      "17.65   19.68   17.71   15.94   14.35   \n",
      "15.88   17.71   15.94   14.35   12.91   \n",
      "14.29   15.94   14.35   12.91   11.62   \n",
      "count 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[21.95416, 24.40413, 21.96371, 19.40413, 17.46371],\n",
       "       [19.75875, 21.96371, 19.76734, 17.79061, 16.01155],\n",
       "       [17.78287, 19.76734, 17.79061, 16.01155, 14.41039],\n",
       "       [16.00459, 17.79061, 16.01155, 14.41039, 12.96935],\n",
       "       [14.40413, 16.01155, 14.41039, 12.96935, 11.67242]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_equation():\n",
    "    gamma = 0.9\n",
    "    # defining possible moves for an agent not in either of the special positions by (mx[i],my[i])\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    # defining possible moves for agent in the special states A and B. special_states gives destination on any move, and special_rewards gives reward\n",
    "    special_states = {}\n",
    "    special_rewards = {}\n",
    "    special_states[(0,1)]=(4,1)\n",
    "    special_rewards[(0,1)]=10\n",
    "    special_states[(0,3)]=(2,3) \n",
    "    special_rewards[(0,3)]=5 \n",
    "    # we will have to solve a system of linear equations of the for ax=b where a is the coefficient matrix and b is the dependent variable value matrix. as there are 25 states, there are 25 V_pi's to solve for, hence a 25x25 matrix of coefficients\n",
    "    coeffs_matrix = np.zeros((25,25))\n",
    "    constants_matrix = np.zeros((25,1))\n",
    "    # iterating over all the states\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            # current state\n",
    "            state = (i,j)\n",
    "            # we can represent each of the 25 states' coeffs in a 5x5 grid, and later unravel it to a 1x25 list \n",
    "            coeffs = np.zeros((5,5))\n",
    "            # our equation for a state i is: v_i = SUM(prob_action*SUM(p(s',r|s,a)*[r + gamma*v_s'])).\n",
    "            # here p(s',r|s,a)=1 for a given s,a as there is only one possible successor state (and corresponding reward) for each state s and action a\n",
    "            coeffs[state]+=1\n",
    "            results = np.zeros((1,1))\n",
    "            for d in range(4):\n",
    "                dx = mx[d]\n",
    "                dy = my[d]\n",
    "                dest = (dx,dy)\n",
    "                new_s = np.add(state,dest) if state not in special_states else special_states[state]\n",
    "                r = get_reward(new_s) if state not in special_states else special_rewards[state]\n",
    "                results[0,0]+=0.25*r\n",
    "                if(r==-1):\n",
    "                    new_s=np.copy(state)\n",
    "                coeffs[new_s[0],new_s[1]]+=-0.25*gamma\n",
    "            #add each state's coeff and constant matrix to the global one\n",
    "            coeffs_matrix[i*5+j,:]=coeffs.ravel()\n",
    "            constants_matrix[i*5+j,:]=results.ravel()\n",
    "    display(coeffs_matrix)\n",
    "    return(coeffs_matrix,constants_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   1.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.90   0.00   0.00   0.00   \n",
      "0.00   -0.23   0.78   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   1.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.90   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   -0.23   0.55   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "-0.23   0.00   0.00   0.00   0.00   0.78   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.78   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.78   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   1.00   -0.23   0.00   0.00   0.00   -0.23   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   0.00   0.00   0.00   0.00   -0.23   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   0.00   0.55   -0.23   0.00   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   -0.23   0.00   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   -0.23   0.00   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.78   -0.23   \n",
      "0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   -0.23   0.00   0.00   0.00   -0.23   0.55   \n"
     ]
    }
   ],
   "source": [
    "a,b=get_linear_equation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 25) (25, 1)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape,b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linalg.solve(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.31   8.79   4.43   5.32   1.49   \n",
      "1.52   2.99   2.25   1.91   0.55   \n",
      "0.05   0.74   0.67   0.36   -0.40   \n",
      "-0.97   -0.44   -0.35   -0.59   -1.18   \n",
      "-1.86   -1.35   -1.23   -1.42   -1.98   \n"
     ]
    }
   ],
   "source": [
    "display(x.reshape(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonlinear_equation():\n",
    "    gamma = 0.9\n",
    "    # defining possible moves for an agent not in either of the special positions by (mx[i],my[i])\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    # defining possible moves for agent in the special states A and B. special_states gives destination on any move, and special_rewards gives reward\n",
    "    special_states = {}\n",
    "    special_rewards = {}\n",
    "    special_states[(0,1)]=(4,1)\n",
    "    special_rewards[(0,1)]=10\n",
    "    special_states[(0,3)]=(2,3) \n",
    "    special_rewards[(0,3)]=5 \n",
    "    # we will have to solve a system of linear equations of the for ax=b where a is the coefficient matrix and b is the dependent variable value matrix. as there are 25 states, there are 25 V_pi's to solve for, hence a 25x25 matrix of coefficients\n",
    "    coeffs_matrix = np.zeros((100,25))\n",
    "    constants_matrix = np.zeros((100,1))\n",
    "    # iterating over all the states\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            # current state\n",
    "            state = (i,j)\n",
    "            # we can represent each of the 25 states' coeffs in a 5x5 grid, and later unravel it to a 1x25 list \n",
    "            coeffs = np.zeros((5,5))\n",
    "            # our equation for a state i is: v_i = SUM(prob_action*SUM(p(s',r|s,a)*[r + gamma*v_s'])).\n",
    "            # here p(s',r|s,a)=1 for a given s,a as there is only one possible successor state (and corresponding reward) for each state s and action a\n",
    "            coeffs[state]+=1\n",
    "            results = np.zeros((1,1))\n",
    "            for d in range(4):\n",
    "                dx = mx[d]\n",
    "                dy = my[d]\n",
    "                dest = (dx,dy)\n",
    "                new_s = np.add(state,dest) if state not in special_states else special_states[state]\n",
    "                r = get_reward(new_s) if state not in special_states else special_rewards[state]\n",
    "                results[0,0]+=0.25*r\n",
    "                if(r==-1):\n",
    "                    new_s=np.copy(state)\n",
    "                coeffs[new_s[0],new_s[1]]+=-0.25*gamma\n",
    "                #add each state's coeff and constant matrix to the global one\n",
    "                coeffs_matrix[i*5+d+j,:]=coeffs.ravel()\n",
    "                constants_matrix[i*5+d+j,:]=results.ravel()\n",
    "#     display(coeffs_matrix)\n",
    "    return(coeffs_matrix,constants_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = get_nonlinear_equation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 100) (100,)\n"
     ]
    }
   ],
   "source": [
    "# import scipy.optimize as opt\n",
    "print(a.T.shape,b.ravel().shape)\n",
    "x = scipy.optimize.linprog(np.dot(np.linalg.inv(np.dot(a.T,a)),np.dot(a.T,-b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     con: array([], dtype=float64)\n",
       "     fun: -inf\n",
       " message: 'The problem is (trivially) unbounded because there are no non-trivial constraints and a) at least one decision variable is unbounded above and its corresponding cost is negative, or b) at least one decision variable is unbounded below and its corresponding cost is positive. '\n",
       "     nit: 0\n",
       "   slack: array([], dtype=float64)\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([ 0., inf,  0., inf,  0.,  0., inf,  0., inf,  0.,  0., inf,  0.,\n",
       "       inf,  0.,  0., inf,  0., inf, inf,  0., inf,  0., inf,  0.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_state(s):\n",
    "    if(s[0]>=0 and s[0]<4):\n",
    "        if(s[1]>=0 and s[1]<4):\n",
    "            return(True)\n",
    "    return(False)\n",
    "def terminal(s):\n",
    "    if(s[0]==0 and s[1]==0):\n",
    "        return(True)\n",
    "    if(s[0]==3 and s[1]==3):\n",
    "        return(True)\n",
    "def policy_evaluation():\n",
    "    gamma = 1\n",
    "    gridworld = np.zeros((4,4))\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    changes = True\n",
    "    count = 0\n",
    "    while(changes):\n",
    "        count+=1\n",
    "        changes= False\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                total = 0\n",
    "                state = (i,j)\n",
    "                if(terminal(state)):\n",
    "                        continue\n",
    "                for d in range(4):\n",
    "                    dx = mx[d]\n",
    "                    dy = my[d]\n",
    "                    dest = (dx,dy) \n",
    "                    new_s = np.add(state,dest) \n",
    "                    if(not valid_state(new_s)):\n",
    "                        new_s=state\n",
    "                    r=-1\n",
    "#                     if(terminal(new_s)):\n",
    "#                         r=0\n",
    "                    r += gamma*gridworld[new_s[0],new_s[1]]\n",
    "                    total+=0.25*r\n",
    "                if(np.abs(total-gridworld[i,j])>np.abs(0.001*gridworld[i,j])):\n",
    "                    changes = True\n",
    "                gridworld[i,j]=total\n",
    "        if(count%10==0):\n",
    "            display(gridworld)\n",
    "            print(\"count\",count)\n",
    "    return(gridworld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00   -7.83   -11.12   -12.23   \n",
      "-7.83   -10.42   -11.77   -11.86   \n",
      "-11.12   -11.77   -11.05   -8.81   \n",
      "-12.23   -11.86   -8.81   0.00   \n",
      "count 10\n",
      "0.00   -11.43   -16.30   -17.93   \n",
      "-11.43   -14.84   -16.57   -16.61   \n",
      "-16.30   -16.57   -15.11   -11.84   \n",
      "-17.93   -16.61   -11.84   0.00   \n",
      "count 20\n",
      "0.00   -12.93   -18.46   -20.30   \n",
      "-12.93   -16.68   -18.57   -18.59   \n",
      "-18.46   -18.57   -16.79   -13.10   \n",
      "-20.30   -18.59   -13.10   0.00   \n",
      "count 30\n",
      "0.00   -13.55   -19.36   -21.29   \n",
      "-13.55   -17.45   -19.40   -19.41   \n",
      "-19.36   -19.40   -17.50   -13.62   \n",
      "-21.29   -19.41   -13.62   0.00   \n",
      "count 40\n",
      "0.00   -13.81   -19.73   -21.71   \n",
      "-13.81   -17.77   -19.75   -19.75   \n",
      "-19.73   -19.75   -17.79   -13.84   \n",
      "-21.71   -19.75   -13.84   0.00   \n",
      "count 50\n"
     ]
    }
   ],
   "source": [
    "grid = policy_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(gridworld):\n",
    "    stable = False\n",
    "    policy = []\n",
    "    mx = [-1,0,0,1]\n",
    "    my = [0,1,-1,0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        policy.append([])\n",
    "        for j in range(4):\n",
    "            policy[i].append([])\n",
    "    while(not stable):\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                state = (i,j)\n",
    "                if(terminal(state)):\n",
    "                    continue\n",
    "                old_action = policy[i][j]\n",
    "                best_value = -np.inf\n",
    "                best_move = None\n",
    "                for d in range(4):\n",
    "                    dest = (mx[d],my[d])\n",
    "                    new_s = np.add(state,dest)\n",
    "                    if(not valid_state(new_s)):\n",
    "                        new_s =  state\n",
    "                    if(gridworld[new_s[0],new_s[1]]>best_value):\n",
    "                        best_value = gridworld[new_s[0],new_s[1]]\n",
    "                        best_move = new_s\n",
    "                policy[i][j]=best_move\n",
    "                stable = True\n",
    "                if(len(old_action)>0):\n",
    "                    print(old_action,best_move)\n",
    "                    if(old_action[0]!=best_move[0] or old_action[1]!=best_move[1]):\n",
    "                        stable=False\n",
    "                else:\n",
    "                    stable=False\n",
    "    return(policy)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] [0 0]\n",
      "[0 1] [0 1]\n",
      "[0 2] [0 2]\n",
      "[0 0] [0 0]\n",
      "[0 1] [0 1]\n",
      "[1 1] [1 1]\n",
      "[2 3] [2 3]\n",
      "[1 0] [1 0]\n",
      "[1 1] [1 1]\n",
      "[2 3] [2 3]\n",
      "[3 3] [3 3]\n",
      "[2 0] [2 0]\n",
      "[3 2] [3 2]\n",
      "[3 3] [3 3]\n"
     ]
    }
   ],
   "source": [
    "p = policy_improvement(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[], array([0, 0]), array([0, 1]), array([0, 2])], [array([0, 0]), array([0, 1]), array([1, 1]), array([2, 3])], [array([1, 0]), array([1, 1]), array([2, 3]), array([3, 3])], [array([2, 0]), array([3, 2]), array([3, 3]), []]]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
